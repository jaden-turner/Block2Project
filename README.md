# Block2Project
Assignment for CS3090 on Choosing a Copyright License w/an Ethical Analysis

### MIT License
This license was chosen for a number of reasons. This repository will likely be used for general coding projects, that I don't seek to make anything off of and don't mind if people use it for their own projects. The MIT license lets others use, copy, modify, merge, publish, distribue, sublicense, and/or sell copies of the code here, only under the condition that the copyright notice and permission notice is included in all copies or portions of the code used elsewhere. As this license is also largely popular on this platform, that provided another good reason to choose it for a repository such as this one.

## Ethical Analyisis
### Utilitarianism
Utilitarian ethics decides right from wrong solely from the outcome of an action, regardless of what that action was. This also means that if an action that seems like a bad thing to do results in a good outcome, it was the right thing to do. In terms of using generative AI for government lobbying, the outcome appears to be that there would be more targeted lobbying, obtaining the “most leverage over a particular policy area.” Depending on one’s perspective, this could be either right or wrong depending on the person's beliefs on good and bad and how it’s used. For example, for someone wanting to have a better outcome for lobbying to get a law passed that they support, this would be the right thing to do for them. On the other hand, if someone was using this for a law that the other person doesn’t support, the other person would see the outcome as not good, and therefore wrong. It might also be safe to say that if both parties had equal access to such an AI to support their lobbying, it would overall be good for both parties because they could both obtain the information they need to do better lobbying.
### Deontology
Deontology ethics decides what is right or wrong from a clear set of laws or rules. In other words, “actions that align with these rules are ethical, while actions that don’t aren’t.” (The Ethics Centre) While some people might not like it, there is nothing from deontology ethics that says using generative AI for lobbying or other political influences is wrong (at least in terms of laws in the United States.) From some religions standpoints, lots of things in politics may be considered unethical like lying, bribing, and other similar actions. It might be easy for some to say that a generative AI used for political use would be unethical as well. On the other hand, using a generative AI is no different than not using it in this case, it only changes the tools and capabilities one would have to make such influences. One article defending against AI Lobbyists states that generative AI like ChatGPT “...[does] not think. They do not have free will. They are just tools directed by people, much like lobbyist for hire. And, like lobbyists, they will be available primarily to the richest individuals, groups, and their interests.” (Defending Against AI Lobbyists) We can conclude by this that using an AI for these things isn’t unethical, but the doing of these political acts is what is unethical.
### Virtue Ethics
Virtue ethics decides right from wrong based on moral philosophy opposed to acting in a way for good results. Such ethics stem from values such as honesty, courage, compassion, generosity, integrity, and fairness. In the article How ChatGPT Hijacks Democracy it mentions how it’s possible that “...this kind of strategy-generating AI could revitalize the democratization of democracy by giving this kind of lobbying power to the powerless.” This would be ethical in this sense because it provides fairness and representation for more people than just those who have the money to spend. But because of that same fact it is limited in its potential for those without money. The best lobbying strategies still require insiders and money, which this AI wouldn’t be able to provide. With that information, the only way to really decide if using this AI for politics is ethical or not is the moral factors behind the users of such an application. For example, if someone used this to generate articles against a specific candidate, regardless of the information generated is true, this would be ethically wrong because it isn’t honest or fair to the person that article is written about. It would be more ethical to have it used to help as a starting point for such articles, which would be followed up with personal research and verification of details to ensure it is honest and fair.
### Personal
It seems like a generative AI could provide a lot of benefits for political figures and others when it comes to lobbying and other politics. Also the cheap nature of such a software would provide accessibility to lobbying that isn’t as available today in its current state. With everything considered, I think there is no real ethical issue with using generative AI in these endeavors. If anything, it just helps speed up the process of lobbying, which will give people more time to focus on other political processes that need more time and attention.I definitely agree with Nathan Sanders when he states how AI is just a tool, and that the only thing that really decides if something is ethical or not is the user and how they are using that tool. Just because you own a knife and it has the potential to do harm doesn’t mean it’s unethical to use. It has many capabilities, for example cooking, which is certainly not unethical. In like manner, generative AI has a plethora of capabilities, it is only determined to be an ethical use of it or not based on the user and their own intentions for right or for wrong.
### Sources
- The Ethics Centre. “Ethics Explainer: What Is Deontology?” THE ETHICS CENTRE, 13 Dec. 2021, https://ethics.org.au/ethics-explainer-deontology/#:~:text=Deontology%20is%20an%20ethical%20theory,don't%20aren't. 
- Sanders, Nathan. “Defending against AI Lobbyists.” Schneier on Security, 17 Feb. 2023, https://www.schneier.com/blog/archives/2023/02/defending-against-ai-lobbyists.html.
- Sanders, Nathan E., and Bruce Schneier. “How CHATGPT Hijacks Democracy.” The New York Times, The New York Times, 15 Jan. 2023, https://www.nytimes.com/2023/01/15/opinion/ai-chatgpt-lobbying-democracy.html. 
